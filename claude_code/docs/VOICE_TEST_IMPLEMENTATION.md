# ìŒì„± ê²€ì‚¬ êµ¬í˜„ ë¬¸ì„œ

## ê°œìš”

OpenAI Realtime APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¬ì¥ ê±´ê°• ê²€ì‚¬ë¥¼ ìŒì„±ìœ¼ë¡œ ì§„í–‰í•˜ëŠ” ê¸°ëŠ¥ì„ êµ¬í˜„í•©ë‹ˆë‹¤. í…ìŠ¤íŠ¸ ì…ë ¥ ë°©ì‹ê³¼ ë™ì¼í•œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³ , ë™ì¼í•œ ë°±ì—”ë“œ APIë¥¼ í†µí•´ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
[React Native App] â†’ [Backend API] â†’ [OpenAI Realtime API]
         â†“                  â†“
   [WebRTC/WebSocket]  [Token Generation]
         â†“                  â†“
   [Audio I/O]        [Data Validation]
         â†“                  â†“
   [User Response]    [DB Storage]
         â†“                  â†“
   [Result Screen]    [Prediction API]
```

## ë¡œì§ íë¦„ ë¶„ì„

### 1. ìŒì„± ê²€ì‚¬ ë‹¨ê³„ êµ¬ì¡°

```typescript
enum VoiceTestPhase {
  INITIALIZATION = 'initialization',    // ì¤€ë¹„ í™•ì¸
  BASIC_INFO = 'basic_info',           // ê¸°ë³¸ ì •ë³´ (6ë¬¸í•­)
  SYMPTOMS = 'symptoms',               // ì¦ìƒ ì²´í¬ (10ë¬¸í•­)
  COMPLETION = 'completion',           // ì™„ë£Œ ë° ê°ì‚¬ ì¸ì‚¬
}

interface Question {
  id: string;
  phase: VoiceTestPhase;
  text: string;
  type: 'yes_no' | 'gender' | 'number' | 'choice';
  options?: string[];
  fieldName: keyof AssessmentData;
  validation?: (value: string) => boolean;
}
```

### 2. ì§ˆë¬¸ ìˆœì„œ ë° ë§¤í•‘

#### Phase 1: ì´ˆê¸°í™” (INITIALIZATION)
```
Q0: ì¤€ë¹„ í™•ì¸
- í…ìŠ¤íŠ¸: "ì‹¬ì¥ ë‹¥í„°ì˜ ì‹¬ì¥ ê±´ê°• ë¶„ì„ ì‹œê°„ì…ë‹ˆë‹¤. ê³ ê°ë‹˜ ì§€ê¸ˆ ì¤€ë¹„ë˜ì…¨ë‚˜ìš”?"
- ì‘ë‹µ: "ì˜ˆ" â†’ ì‹œì‘ / "ì•„ë‹ˆì˜¤" â†’ ì·¨ì†Œ
- ë§¤í•‘: N/A (ì‹œì‘ íŠ¸ë¦¬ê±°)
```

#### Phase 2: ê¸°ë³¸ ì •ë³´ (BASIC_INFO)
```
Q1: ì„±ë³„ â†’ gender
- ì‘ë‹µ: "ë‚¨ì" | "ì—¬ì" â†’ "male" | "female"

Q2: ë‚˜ì´ â†’ age
- ì‘ë‹µ: ìˆ«ì (ì˜ˆ: "ìŠ¤ë¬¼ë‹¤ì„¯" â†’ "25")

Q3: ëª¸ë¬´ê²Œ â†’ weight
- ì‘ë‹µ: ìˆ«ì (ì˜ˆ: "ì¹ ì‹­" â†’ "70")

Q4: í‚¤ â†’ height
- ì‘ë‹µ: ìˆ«ì (ì˜ˆ: "ë°±ì¹ ì‹­ì˜¤" â†’ "175")

Q5: ì²´ì˜¨ â†’ bodyTemperature
- ì‘ë‹µ: "ë‚®ë‹¤" | "ë³´í†µ" | "ë†’ë‹¤" â†’ "low" | "normal" | "high"

Q6: í˜¸í¡ â†’ breathing
- ì‘ë‹µ: "ëŠë¦¬ë‹¤" | "ë³´í†µ" | "ë¹ ë¥´ë‹¤" â†’ "slow" | "normal" | "fast"
```

#### Phase 3: ì¦ìƒ ì²´í¬ (SYMPTOMS)
```
Q7: ê°€ìŠ´ í†µì¦ â†’ chestPain
Q8: ì˜†êµ¬ë¦¬/ë“± í†µì¦ â†’ flankPain
Q9: ë°œ í†µì¦ â†’ footPain
Q10: ë°œ ë¶€ì¢… â†’ edemaLegs
Q11: í˜¸í¡ê³¤ë€ â†’ dyspnea
Q12: ì‹¤ì‹  â†’ syncope
Q13: í”¼ë¡œê° â†’ weakness
Q14: êµ¬í†  â†’ vomiting
Q15: ì‹¬ì¥ ë‘ê·¼ê±°ë¦¼ â†’ palpitation
Q16: ì–´ì§€ëŸ¬ì›€ â†’ dizziness

ëª¨ë‘ ì‘ë‹µ: "ì˜ˆ" | "ì•„ë‹ˆì˜¤" â†’ "yes" | "no"
```

### 3. ë°ì´í„° ë³€í™˜ ë¡œì§

```typescript
interface VoiceResponse {
  transcript: string;      // ì‚¬ìš©ì ìŒì„± í…ìŠ¤íŠ¸
  confidence: number;      // ì¸ì‹ ì‹ ë¢°ë„
  timestamp: Date;         // ì‘ë‹µ ì‹œê°„
}

interface ParsedResponse {
  value: string;          // ì •ê·œí™”ëœ ê°’
  isValid: boolean;       // ìœ íš¨ì„± ì—¬ë¶€
  originalText: string;   // ì›ë³¸ í…ìŠ¤íŠ¸
}

// ìŒì„± ì‘ë‹µ â†’ AssessmentData ë³€í™˜
function parseVoiceResponse(
  question: Question,
  response: VoiceResponse
): ParsedResponse {
  // 1. í…ìŠ¤íŠ¸ ì •ê·œí™”
  const normalized = normalizeKoreanText(response.transcript);

  // 2. íƒ€ì…ë³„ íŒŒì‹±
  switch (question.type) {
    case 'yes_no':
      return parseYesNo(normalized);
    case 'gender':
      return parseGender(normalized);
    case 'number':
      return parseKoreanNumber(normalized);
    case 'choice':
      return parseChoice(normalized, question.options);
  }
}
```

## ë°±ì—”ë“œ êµ¬í˜„

### 1. OpenAI Realtime API í† í° ìƒì„±

#### Endpoint: `POST /api/v1/voice/token`

```java
@RestController
@RequestMapping("/api/v1/voice")
public class VoiceTestController {

    @Autowired
    private OpenAIRealtimeService openAIService;

    @PostMapping("/token")
    @PreAuthorize("isAuthenticated()")
    public ResponseEntity<TokenResponse> generateToken(
        @RequestHeader("Authorization") String token
    ) {
        // 1. ì‚¬ìš©ì ì¸ì¦ í™•ì¸
        User user = authService.getUserFromToken(token);

        // 2. OpenAI ephemeral token ìƒì„±
        String ephemeralToken = openAIService.generateClientSecret();

        // 3. ì„¸ì…˜ ë©”íƒ€ë°ì´í„° ì €ì¥ (optional)
        VoiceSession session = voiceSessionService.createSession(
            user.getId(),
            ephemeralToken
        );

        return ResponseEntity.ok(new TokenResponse(
            ephemeralToken,
            session.getSessionId()
        ));
    }
}
```

#### Service êµ¬í˜„

```java
@Service
public class OpenAIRealtimeService {

    @Value("${openai.api.key}")
    private String apiKey;

    private static final String TOKEN_URL =
        "https://api.openai.com/v1/realtime/client_secrets";

    public String generateClientSecret() {
        // Session configuration
        Map<String, Object> sessionConfig = Map.of(
            "session", Map.of(
                "type", "realtime",
                "model", "gpt-realtime-mini-2025-10-06",
                "audio", Map.of(
                    "output", Map.of("voice", "alloy")
                ),
                "instructions", buildInstructions()
            )
        );

        // HTTP Request
        HttpHeaders headers = new HttpHeaders();
        headers.set("Authorization", "Bearer " + apiKey);
        headers.setContentType(MediaType.APPLICATION_JSON);

        HttpEntity<Map<String, Object>> request =
            new HttpEntity<>(sessionConfig, headers);

        ResponseEntity<TokenResponse> response = restTemplate.postForEntity(
            TOKEN_URL,
            request,
            TokenResponse.class
        );

        return response.getBody().getValue();
    }

    private String buildInstructions() {
        return """
            ë‹¹ì‹ ì€ ì‹¬ì¥ ê±´ê°• ê²€ì‚¬ë¥¼ ì§„í–‰í•˜ëŠ” ì˜ë£Œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

            ê·œì¹™:
            1. í•­ìƒ ì •ì¤‘í•˜ê³  ì¹œì ˆí•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš”
            2. í•œ ë²ˆì— í•˜ë‚˜ì˜ ì§ˆë¬¸ë§Œ í•˜ì„¸ìš”
            3. ì‚¬ìš©ì ë‹µë³€ì„ ëª…í™•í•˜ê²Œ ì´í•´í•˜ì§€ ëª»í•œ ê²½ìš°, ë‹¤ì‹œ ì§ˆë¬¸í•˜ì„¸ìš”
            4. ìˆ«ìëŠ” ì •í™•í•˜ê²Œ íŒŒì•…í•˜ì„¸ìš” (ì˜ˆ: "ìŠ¤ë¬¼ë‹¤ì„¯" â†’ 25)
            5. ì˜ˆ/ì•„ë‹ˆì˜¤ ì§ˆë¬¸ì—ëŠ” ëª…í™•í•œ ë‹µë³€ì„ ìš”ì²­í•˜ì„¸ìš”

            ì§ˆë¬¸ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìˆœì„œëŒ€ë¡œ ë”°ë¼ê°€ë©°, ê° ë‹µë³€ì„ ì •í™•í•˜ê²Œ ê¸°ë¡í•˜ì„¸ìš”.
            """;
    }
}
```

### 2. ë°ì´í„° ì €ì¥ ì—”ë“œí¬ì¸íŠ¸

ìŒì„± ê²€ì‚¬ ê²°ê³¼ëŠ” ê¸°ì¡´ `/api/v1/checks` ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.

```java
// ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
POST /api/v1/checks
{
  "gender": "male",
  "age": "25",
  "height": "175",
  "weight": "70",
  "bodyTemperature": "normal",
  "breathing": "normal",
  "pulse": "75",  // ìŒì„± ê²€ì‚¬ì—ì„œëŠ” ìë™ ê³„ì‚° ë˜ëŠ” ê¸°ë³¸ê°’
  "chestPain": "no",
  "flankPain": "no",
  // ... ë‚˜ë¨¸ì§€ ì¦ìƒ
}
```

### 3. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ (ì„ íƒì )

ìŒì„± ê²€ì‚¬ ì„¸ì…˜ ì¶”ì ì„ ìœ„í•œ í…Œì´ë¸” (optional):

```sql
CREATE TABLE voice_test_sessions (
    session_id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL REFERENCES users(user_id),
    openai_session_id VARCHAR(255),
    ephemeral_token VARCHAR(500),
    status VARCHAR(50) NOT NULL, -- 'active', 'completed', 'cancelled'
    started_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP,
    audio_duration_seconds INTEGER,
    check_id BIGINT REFERENCES checks(check_id),
    FOREIGN KEY (user_id) REFERENCES users(user_id)
);

CREATE INDEX idx_voice_sessions_user ON voice_test_sessions(user_id);
CREATE INDEX idx_voice_sessions_status ON voice_test_sessions(status);
```

## í”„ë¡ íŠ¸ì—”ë“œ êµ¬í˜„

### 1. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
cd frontend
npm install @openai/realtime-api-beta
npm install @react-native-community/audio-toolkit  # or similar
```

### 2. íŒŒì¼ êµ¬ì¡°

```
frontend/src/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ voiceTestService.ts          # OpenAI Realtime API ì—°ë™
â”‚   â””â”€â”€ audioService.ts               # ì˜¤ë””ì˜¤ ì…ì¶œë ¥ ê´€ë¦¬
â”œâ”€â”€ hooks/
â”‚   â”œâ”€â”€ useVoiceTest.ts              # ìŒì„± ê²€ì‚¬ ë¡œì§
â”‚   â””â”€â”€ useAudioPermission.ts        # ê¶Œí•œ ê´€ë¦¬
â”œâ”€â”€ screens/main/
â”‚   â””â”€â”€ VoiceTestModeScreen.tsx      # ê¸°ì¡´ íŒŒì¼ ì—…ë°ì´íŠ¸
â””â”€â”€ constants/
    â””â”€â”€ voiceTestQuestions.ts        # ì§ˆë¬¸ ë°ì´í„°
```

### 3. ì§ˆë¬¸ ë°ì´í„° êµ¬ì¡°

```typescript
// constants/voiceTestQuestions.ts
export const VOICE_TEST_QUESTIONS: Question[] = [
  // Phase 0: Initialization
  {
    id: 'init',
    phase: VoiceTestPhase.INITIALIZATION,
    text: 'ì‹¬ì¥ ë‹¥í„°ì˜ ì‹¬ì¥ ê±´ê°• ë¶„ì„ ì‹œê°„ì…ë‹ˆë‹¤. ê³ ê°ë‹˜ ì§€ê¸ˆ ì¤€ë¹„ë˜ì…¨ë‚˜ìš”? ì¤€ë¹„ë˜ì…¨ìœ¼ë©´ "ì˜ˆ"ë¼ê³  ë§ì”€í•´ ì£¼ì„¸ìš”. í˜¹ì‹œ ë‹µë³€ ì¤€ë¹„ê°€ ì•ˆ ë˜ì—ˆê±°ë‚˜ ë¶„ì„ì„ ì·¨ì†Œí•˜ë ¤ë©´ "ì•„ë‹ˆì˜¤"ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.',
    type: 'yes_no',
    fieldName: null,
  },

  // Phase 1: Basic Info
  {
    id: 'gender',
    phase: VoiceTestPhase.BASIC_INFO,
    text: 'ê³ ê°ë‹˜ì˜ ì„±ë³„ì„ ë§ì”€í•´ ì£¼ì„¸ìš”. "ë‚¨ì" í˜¹ì€ "ì—¬ì"ë¼ê³  ë§ì”€í•´ ì£¼ì„¸ìš”.',
    type: 'gender',
    fieldName: 'gender',
    validation: (value) => ['male', 'female'].includes(value),
  },
  {
    id: 'age',
    phase: VoiceTestPhase.BASIC_INFO,
    text: 'ê³ ê°ë‹˜ì˜ ë‚˜ì´ëŠ” ëª‡ ì„¸ì¸ê°€ìš”? ìˆ«ìë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”.',
    type: 'number',
    fieldName: 'age',
    validation: (value) => {
      const num = parseInt(value);
      return !isNaN(num) && num > 0 && num < 150;
    },
  },
  {
    id: 'weight',
    phase: VoiceTestPhase.BASIC_INFO,
    text: 'ê³ ê°ë‹˜ì˜ ëª¸ë¬´ê²ŒëŠ” ëª‡ kgì¸ê°€ìš”? ìˆ«ìë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”.',
    type: 'number',
    fieldName: 'weight',
    validation: (value) => {
      const num = parseInt(value);
      return !isNaN(num) && num > 20 && num < 300;
    },
  },
  // ... ë‚˜ë¨¸ì§€ ì§ˆë¬¸ë“¤
];
```

### 4. ìŒì„± ê²€ì‚¬ ì„œë¹„ìŠ¤

```typescript
// services/voiceTestService.ts
import { RealtimeClient } from '@openai/realtime-api-beta';

interface VoiceTestConfig {
  onQuestionStart: (question: Question) => void;
  onResponseReceived: (transcript: string) => void;
  onAnswerValidated: (field: string, value: string) => void;
  onTestComplete: (data: AssessmentData) => void;
  onError: (error: Error) => void;
}

export class VoiceTestService {
  private client: RealtimeClient;
  private currentQuestionIndex: number = 0;
  private assessmentData: Partial<AssessmentData> = {};
  private config: VoiceTestConfig;

  constructor(config: VoiceTestConfig) {
    this.config = config;
    this.client = new RealtimeClient({
      apiKey: '', // Will be set during initialization
      dangerouslyAllowAPIKeyInBrowser: true, // Use ephemeral token instead
    });
  }

  async initialize(ephemeralToken: string): Promise<void> {
    try {
      // Connect to OpenAI Realtime API
      await this.client.connect({
        apiKey: ephemeralToken,
      });

      // Configure session
      await this.client.updateSession({
        instructions: this.buildInstructions(),
        voice: 'alloy',
        input_audio_transcription: {
          model: 'whisper-1',
        },
      });

      // Set up event listeners
      this.setupEventListeners();

      // Start first question
      await this.askNextQuestion();
    } catch (error) {
      this.config.onError(error);
      throw error;
    }
  }

  private setupEventListeners(): void {
    // Listen for user responses
    this.client.on('conversation.item.completed', async (event) => {
      if (event.item.role === 'user') {
        const transcript = event.item.content[0].transcript;
        this.config.onResponseReceived(transcript);

        // Parse and validate response
        await this.handleUserResponse(transcript);
      }
    });

    // Listen for assistant responses
    this.client.on('conversation.item.completed', (event) => {
      if (event.item.role === 'assistant') {
        // Assistant finished speaking
        console.log('Assistant:', event.item.content[0].transcript);
      }
    });

    // Error handling
    this.client.on('error', (error) => {
      this.config.onError(error);
    });
  }

  private async askNextQuestion(): Promise<void> {
    if (this.currentQuestionIndex >= VOICE_TEST_QUESTIONS.length) {
      await this.completeTest();
      return;
    }

    const question = VOICE_TEST_QUESTIONS[this.currentQuestionIndex];
    this.config.onQuestionStart(question);

    // Send question to assistant
    await this.client.sendUserMessageContent([
      { type: 'input_text', text: question.text },
    ]);
  }

  private async handleUserResponse(transcript: string): Promise<void> {
    const question = VOICE_TEST_QUESTIONS[this.currentQuestionIndex];

    // Parse response based on question type
    const parsed = this.parseResponse(question, transcript);

    if (!parsed.isValid) {
      // Ask again if invalid
      await this.client.sendUserMessageContent([
        {
          type: 'input_text',
          text: 'ì£„ì†¡í•©ë‹ˆë‹¤. ë‹¤ì‹œ í•œ ë²ˆ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?',
        },
      ]);
      return;
    }

    // Store answer
    if (question.fieldName) {
      this.assessmentData[question.fieldName] = parsed.value;
      this.config.onAnswerValidated(question.fieldName, parsed.value);
    }

    // Move to next question
    this.currentQuestionIndex++;
    await this.askNextQuestion();
  }

  private parseResponse(
    question: Question,
    transcript: string
  ): ParsedResponse {
    const normalized = transcript.toLowerCase().trim();

    switch (question.type) {
      case 'yes_no':
        return this.parseYesNo(normalized);
      case 'gender':
        return this.parseGender(normalized);
      case 'number':
        return this.parseNumber(normalized);
      case 'choice':
        return this.parseChoice(normalized, question.options);
      default:
        return { value: normalized, isValid: false, originalText: transcript };
    }
  }

  private parseYesNo(text: string): ParsedResponse {
    if (text.includes('ì˜ˆ') || text.includes('ë„¤') || text.includes('yes')) {
      return { value: 'yes', isValid: true, originalText: text };
    }
    if (text.includes('ì•„ë‹ˆ') || text.includes('no')) {
      return { value: 'no', isValid: true, originalText: text };
    }
    return { value: text, isValid: false, originalText: text };
  }

  private parseGender(text: string): ParsedResponse {
    if (text.includes('ë‚¨') || text.includes('male')) {
      return { value: 'male', isValid: true, originalText: text };
    }
    if (text.includes('ì—¬') || text.includes('female')) {
      return { value: 'female', isValid: true, originalText: text };
    }
    return { value: text, isValid: false, originalText: text };
  }

  private parseNumber(text: string): ParsedResponse {
    // Try direct number extraction
    const numberMatch = text.match(/\d+/);
    if (numberMatch) {
      return {
        value: numberMatch[0],
        isValid: true,
        originalText: text,
      };
    }

    // Try Korean number parsing
    const koreanNumber = this.parseKoreanNumber(text);
    if (koreanNumber !== null) {
      return {
        value: koreanNumber.toString(),
        isValid: true,
        originalText: text,
      };
    }

    return { value: text, isValid: false, originalText: text };
  }

  private parseKoreanNumber(text: string): number | null {
    // Korean number parsing logic
    // ì˜ˆ: "ìŠ¤ë¬¼ë‹¤ì„¯" â†’ 25, "ì¼ë°±ì¹ ì‹­ì˜¤" â†’ 175
    const koreanNumbers = {
      ì˜: 0, ì¼: 1, ì´: 2, ì‚¼: 3, ì‚¬: 4,
      ì˜¤: 5, ìœ¡: 6, ì¹ : 7, íŒ”: 8, êµ¬: 9,
      ì‹­: 10, ë°±: 100, ì²œ: 1000,
      ìŠ¤ë¬¼: 20, ì„œë¥¸: 30, ë§ˆí”: 40,
      ì‰°: 50, ì˜ˆìˆœ: 60, ì¼í”: 70,
      ì—¬ë“ : 80, ì•„í”: 90,
    };

    // Implementation needed
    return null;
  }

  private parseChoice(
    text: string,
    options: string[]
  ): ParsedResponse {
    for (const option of options) {
      if (text.includes(option)) {
        return { value: option, isValid: true, originalText: text };
      }
    }
    return { value: text, isValid: false, originalText: text };
  }

  private async completeTest(): Promise<void> {
    // Add default pulse value if not collected
    if (!this.assessmentData.pulse) {
      this.assessmentData.pulse = '75'; // Default value
    }

    // Validate all required fields
    const isComplete = this.validateAssessmentData(
      this.assessmentData as AssessmentData
    );

    if (isComplete) {
      this.config.onTestComplete(this.assessmentData as AssessmentData);
    } else {
      this.config.onError(
        new Error('Incomplete assessment data')
      );
    }
  }

  private validateAssessmentData(data: AssessmentData): boolean {
    const requiredFields: (keyof AssessmentData)[] = [
      'gender', 'age', 'height', 'weight',
      'bodyTemperature', 'breathing',
      'chestPain', 'flankPain', 'footPain',
      'edemaLegs', 'dyspnea', 'syncope',
      'weakness', 'vomiting', 'palpitation', 'dizziness',
    ];

    return requiredFields.every(field => {
      const value = data[field];
      return value !== undefined && value !== null && value !== '';
    });
  }

  async disconnect(): Promise<void> {
    await this.client.disconnect();
  }

  private buildInstructions(): string {
    return `
ë‹¹ì‹ ì€ ì‹¬ì¥ ê±´ê°• ê²€ì‚¬ë¥¼ ì§„í–‰í•˜ëŠ” ì¹œì ˆí•œ ì˜ë£Œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

ê·œì¹™:
1. í•­ìƒ ì •ì¤‘í•˜ê³  ì¹œì ˆí•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš”
2. í•œ ë²ˆì— í•˜ë‚˜ì˜ ì§ˆë¬¸ë§Œ í•˜ì„¸ìš”
3. ì‚¬ìš©ìì˜ ë‹µë³€ì„ ëª…í™•í•˜ê²Œ ì´í•´í•˜ì§€ ëª»í•œ ê²½ìš°, ì •ì¤‘í•˜ê²Œ ë‹¤ì‹œ ì§ˆë¬¸í•˜ì„¸ìš”
4. ìˆ«ìëŠ” ì •í™•í•˜ê²Œ íŒŒì•…í•˜ì„¸ìš”
5. ì˜ˆ/ì•„ë‹ˆì˜¤ ì§ˆë¬¸ì—ëŠ” ëª…í™•í•œ ë‹µë³€ì„ ìš”ì²­í•˜ì„¸ìš”
6. ê° ì§ˆë¬¸ ì „ì— ì§§ì€ í˜¸í¡ì„ ë‘ì„¸ìš”

ì§„í–‰ ë°©ì‹:
- ì œê³µëœ ì§ˆë¬¸ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìˆœì„œëŒ€ë¡œ ë”°ë¼ê°€ì„¸ìš”
- ê° ë‹µë³€ì„ ì •í™•í•˜ê²Œ ë“£ê³  í™•ì¸í•˜ì„¸ìš”
- ë¶ˆë¶„ëª…í•œ ë‹µë³€ì€ ì¬ì§ˆë¬¸í•˜ì„¸ìš”
    `.trim();
  }
}
```

### 5. React Hook êµ¬í˜„

```typescript
// hooks/useVoiceTest.ts
export function useVoiceTest() {
  const [isInitialized, setIsInitialized] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [currentQuestion, setCurrentQuestion] = useState<Question | null>(null);
  const [assessmentData, setAssessmentData] = useState<Partial<AssessmentData>>({});
  const [error, setError] = useState<string | null>(null);
  const [lastTranscript, setLastTranscript] = useState<string>('');

  const voiceService = useRef<VoiceTestService | null>(null);
  const navigation = useNavigation();

  const initializeVoiceTest = async () => {
    try {
      // 1. Get ephemeral token from backend
      const response = await fetch(`${API_BASE_URL}/api/v1/voice/token`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${await getAccessToken()}`,
          'Content-Type': 'application/json',
        },
      });

      const { ephemeralToken } = await response.json();

      // 2. Initialize voice service
      voiceService.current = new VoiceTestService({
        onQuestionStart: (question) => {
          setCurrentQuestion(question);
          console.log('[Voice Test] Question:', question.text);
        },
        onResponseReceived: (transcript) => {
          setLastTranscript(transcript);
          console.log('[Voice Test] User said:', transcript);
        },
        onAnswerValidated: (field, value) => {
          setAssessmentData(prev => ({ ...prev, [field]: value }));
          console.log('[Voice Test] Answer recorded:', field, value);
        },
        onTestComplete: async (data) => {
          console.log('[Voice Test] Complete:', data);
          await handleTestComplete(data);
        },
        onError: (err) => {
          console.error('[Voice Test] Error:', err);
          setError(err.message);
          Alert.alert('ì˜¤ë¥˜', 'ìŒì„± ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
        },
      });

      await voiceService.current.initialize(ephemeralToken);
      setIsInitialized(true);
      setIsRecording(true);
    } catch (err) {
      console.error('[Voice Test] Initialization error:', err);
      setError(err.message);
      Alert.alert('ì˜¤ë¥˜', 'ìŒì„± ê²€ì‚¬ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
    }
  };

  const handleTestComplete = async (data: AssessmentData) => {
    try {
      setIsRecording(false);

      // Submit to backend (same as text mode)
      const response = await submitCheck(data);

      // Navigate to result screen
      navigation.navigate('Result', {
        checkData: response,
        assessmentData: data,
      });
    } catch (err) {
      console.error('[Voice Test] Submit error:', err);
      Alert.alert('ì˜¤ë¥˜', 'ê²€ì‚¬ ê²°ê³¼ ì œì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
    }
  };

  const stopVoiceTest = async () => {
    if (voiceService.current) {
      await voiceService.current.disconnect();
      setIsRecording(false);
    }
  };

  useEffect(() => {
    return () => {
      // Cleanup on unmount
      if (voiceService.current) {
        voiceService.current.disconnect();
      }
    };
  }, []);

  return {
    isInitialized,
    isRecording,
    currentQuestion,
    assessmentData,
    lastTranscript,
    error,
    initializeVoiceTest,
    stopVoiceTest,
  };
}
```

### 6. UI ì—…ë°ì´íŠ¸

```typescript
// screens/main/VoiceTestModeScreen.tsx
export const VoiceTestModeScreen = () => {
  const {
    isInitialized,
    isRecording,
    currentQuestion,
    assessmentData,
    lastTranscript,
    error,
    initializeVoiceTest,
    stopVoiceTest,
  } = useVoiceTest();

  const handleStartVoiceTest = async () => {
    // Check audio permissions
    const hasPermission = await requestAudioPermission();
    if (!hasPermission) {
      Alert.alert('ê¶Œí•œ í•„ìš”', 'ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
      return;
    }

    await initializeVoiceTest();
  };

  const handleCancelTest = () => {
    Alert.alert(
      'ê²€ì‚¬ ì·¨ì†Œ',
      'ìŒì„± ê²€ì‚¬ë¥¼ ì·¨ì†Œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?',
      [
        { text: 'ê³„ì†í•˜ê¸°', style: 'cancel' },
        {
          text: 'ì·¨ì†Œ',
          style: 'destructive',
          onPress: async () => {
            await stopVoiceTest();
            navigation.goBack();
          },
        },
      ]
    );
  };

  return (
    <View style={styles.container}>
      <AppHeader />

      <ScrollView style={styles.content}>
        {!isRecording ? (
          // Initial state - show start button
          <View style={styles.initialState}>
            {/* ... existing UI ... */}
            <TouchableOpacity
              style={styles.startButton}
              onPress={handleStartVoiceTest}>
              <Icon name="mic" size={20} color="#FFFFFF" />
              <Text style={styles.startButtonText}>ìŒì„± ê²€ì‚¬ ì‹œì‘í•˜ê¸°</Text>
            </TouchableOpacity>
          </View>
        ) : (
          // Recording state - show progress
          <View style={styles.recordingState}>
            {/* Animated microphone */}
            <View style={styles.recordingIndicator}>
              <Animated.View style={[styles.pulseCircle, pulseAnimation]} />
              <Icon name="mic" size={60} color="#FFFFFF" />
            </View>

            {/* Current question */}
            {currentQuestion && (
              <View style={styles.questionContainer}>
                <Text style={styles.questionText}>
                  {currentQuestion.text}
                </Text>
              </View>
            )}

            {/* Last transcript */}
            {lastTranscript && (
              <View style={styles.transcriptContainer}>
                <Text style={styles.transcriptLabel}>ë“¤ì€ ë‚´ìš©:</Text>
                <Text style={styles.transcriptText}>{lastTranscript}</Text>
              </View>
            )}

            {/* Progress indicator */}
            <View style={styles.progressContainer}>
              <Text style={styles.progressText}>
                {Object.keys(assessmentData).length} / 16 ì™„ë£Œ
              </Text>
              <View style={styles.progressBar}>
                <View
                  style={[
                    styles.progressFill,
                    {
                      width: `${(Object.keys(assessmentData).length / 16) * 100}%`,
                    },
                  ]}
                />
              </View>
            </View>

            {/* Cancel button */}
            <TouchableOpacity
              style={styles.cancelButton}
              onPress={handleCancelTest}>
              <Text style={styles.cancelButtonText}>ê²€ì‚¬ ì·¨ì†Œ</Text>
            </TouchableOpacity>
          </View>
        )}
      </ScrollView>
    </View>
  );
};
```

## ê°œë°œ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Backend âœ… ì™„ë£Œ

- [x] **OpenAI Integration**
  - [x] OpenAI API Key í™˜ê²½ë³€ìˆ˜ ì„¤ì • (`application.properties`)
  - [x] OpenAIRealtimeService êµ¬í˜„ (`OpenAIRealtimeService.java`)
  - [x] Token generation endpoint êµ¬í˜„ (`VoiceTestController.java`)
  - [x] Error handling ë° retry logic

- [x] **API Endpoints**
  - [x] `POST /api/v1/voice/token` êµ¬í˜„ (JWT ì¸ì¦ í†µí•©)
  - [x] ê¸°ì¡´ `POST /api/v1/prediction` ì¬ì‚¬ìš© í™•ì¸
  - [x] Authentication ë¯¸ë“¤ì›¨ì–´ ì ìš© (`@PreAuthorize`)

- [x] **Configuration**
  - [x] RestTemplate ì„¤ì • (`RestTemplateConfig.java`)
  - [x] DTO í´ë˜ìŠ¤ ìƒì„± (TokenResponse, OpenAITokenRequest, OpenAITokenResponse)
  - [x] í•œê¸€ ì‹œìŠ¤í…œ ì§€ì‹œë¬¸ ì‘ì„±

- [x] **Testing**
  - [x] ë°±ì—”ë“œ ì»´íŒŒì¼ ì„±ê³µ
  - [x] Token generation endpoint ìƒì„± í™•ì¸
  - [x] Spring Boot ì„œë²„ ì‹œì‘ ì„±ê³µ

### Frontend âœ… ì™„ë£Œ

- [x] **Dependencies**
  - [x] WebSocket ë„¤ì´í‹°ë¸Œ ì§€ì› (React Native)
  - [x] react-native-permissions ì„¤ì¹˜ ì™„ë£Œ
  - [x] ì¶”ê°€ íŒ¨í‚¤ì§€ ë¶ˆí•„ìš” (OpenAI beta íŒ¨í‚¤ì§€ ëŒ€ì‹  ì§ì ‘ WebSocket ì‚¬ìš©)

- [x] **Core Implementation**
  - [x] voiceTestQuestions.ts ì‘ì„± (17ê°œ ì§ˆë¬¸ + ë§¤í•‘)
  - [x] VoiceTestService í´ë˜ìŠ¤ êµ¬í˜„ (WebSocket ê¸°ë°˜)
  - [x] useVoiceTest hook êµ¬í˜„ (7ê°€ì§€ ìƒíƒœ ê´€ë¦¬)
  - [x] Audio permission handling (Android/iOS)

- [x] **Parsing Logic**
  - [x] Yes/No parser êµ¬í˜„ (`parseYesNo`)
  - [x] Gender parser êµ¬í˜„ (`parseSex`)
  - [x] Number parser êµ¬í˜„ (`parseVoiceNumber`)
  - [x] Korean number parser êµ¬í˜„ (ê¸°ë³¸ ìˆ«ì ë‹¨ì–´ ì§€ì›)
  - [x] Response validation êµ¬í˜„

- [x] **UI Components**
  - [x] VoiceTestModeScreen ì—…ë°ì´íŠ¸ (ì™„ì „ ì¬êµ¬í˜„)
  - [x] Recording indicator êµ¬í˜„ (ìƒíƒœë³„ ë§ˆì´í¬ ì•„ì´ì½˜)
  - [x] Progress bar êµ¬í˜„ (0-17 ì§„í–‰ë¥ )
  - [x] Transcript display (ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ê²°ê³¼)
  - [x] Error states ì²˜ë¦¬ (ì¬ì‹œë„, ì—ëŸ¬ í™”ë©´)

- [x] **State Management**
  - [x] 7ê°€ì§€ ìƒíƒœ: idle, connecting, ready, listening, processing, speaking, completed, error
  - [x] ìƒíƒœë³„ UI ë Œë”ë§ í•¨ìˆ˜
  - [x] ìƒíƒœ ì „í™˜ ë¡œì§

- [x] **Navigation**
  - [x] Result screen navigation (ìë™ ì œì¶œ í›„ ì´ë™)
  - [x] Cancel/back handling (í™•ì¸ ë‹¤ì´ì–¼ë¡œê·¸)
  - [x] í…ìŠ¤íŠ¸ ëª¨ë“œ ì „í™˜ (í™•ì¸ ë‹¤ì´ì–¼ë¡œê·¸)

- [x] **Testing**
  - [x] Navigation ì •ìƒ ë™ì‘ í™•ì¸
  - [x] Metro bundler ì‹¤í–‰ í™•ì¸
  - [x] VoiceTestService ì´ˆê¸°í™” ë¡œê·¸ í™•ì¸
  - [ ] Full flow E2E í…ŒìŠ¤íŠ¸ (ë‹¤ìŒ ë‹¨ê³„)

### Integration ğŸ”„ ì§„í–‰ ì¤‘

- [x] **Core Flow**
  - [x] Token generation â†’ Session init
  - [x] WebSocket ì—°ê²° ë¡œì§
  - [x] Response parsing â†’ Data collection
  - [x] Submit â†’ Result display
  - [ ] Audio streaming (ì‹¤ì œ í…ŒìŠ¤íŠ¸ í•„ìš”)

- [x] **Error Handling**
  - [x] Network errors
  - [x] OpenAI API errors
  - [x] Permission denied
  - [x] Timeout handling

- [ ] **Edge Cases** (ì‹¤ì œ í…ŒìŠ¤íŠ¸ í•„ìš”)
  - [ ] App backgrounding
  - [ ] Network interruption
  - [ ] Invalid responses
  - [ ] Incomplete sessions

### DevOps ğŸ“‹ ëŒ€ê¸° ì¤‘

- [x] **Environment Setup**
  - [x] OpenAI API key ì„¤ì • (dev)
  - [ ] Rate limiting ì„¤ì •
  - [ ] Monitoring ì„¤ì •

- [ ] **Deployment**
  - [ ] Backend deployment
  - [ ] App update ë°°í¬
  - [ ] Feature flag (ì„ íƒì )

## ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

1. **API Key ê´€ë¦¬**
   - Backendì—ì„œë§Œ OpenAI API key ì‚¬ìš©
   - Ephemeral tokenì€ í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì•ˆì „í•˜ê²Œ ì‚¬ìš© ê°€ëŠ¥
   - Token ë§Œë£Œ ì‹œê°„ ì ì ˆíˆ ì„¤ì •

2. **ë°ì´í„° ë³´ì•ˆ**
   - ìŒì„± ë°ì´í„°ëŠ” OpenAI ì„œë²„ì—ì„œ ì²˜ë¦¬
   - TranscriptëŠ” í•„ìš”ì‹œì—ë§Œ ì €ì¥
   - HIPAA/ì˜ë£Œ ë°ì´í„° ê·œì • ì¤€ìˆ˜

3. **Rate Limiting**
   - ì‚¬ìš©ìë‹¹ ì¼ì¼ ìŒì„± ê²€ì‚¬ íšŸìˆ˜ ì œí•œ
   - Abuse ë°©ì§€ ë¡œì§

## ì„±ëŠ¥ ìµœì í™”

1. **Network Optimization**
   - WebRTC ìš°ì„  ì‚¬ìš© (ë‚®ì€ latency)
   - Fallback to WebSocket

2. **Audio Quality**
   - ì ì ˆí•œ ìƒ˜í”Œ ë ˆì´íŠ¸ ì„¤ì •
   - Noise cancellation

3. **Caching**
   - ì§ˆë¬¸ ë°ì´í„° ë¡œì»¬ ìºì‹±
   - Token ì¬ì‚¬ìš© (ë§Œë£Œ ì „)

## ëª¨ë‹ˆí„°ë§ ë° ë¶„ì„

1. **Metrics**
   - Session completion rate
   - Average session duration
   - Error rates by type
   - OpenAI API usage

2. **User Analytics**
   - Voice vs Text mode usage
   - Question completion rates
   - Drop-off points

## êµ¬í˜„ ì™„ë£Œ íŒŒì¼ ëª©ë¡

### Backend íŒŒì¼

1. **Configuration**
   - `backend/src/main/resources/application.properties` - OpenAI API ì„¤ì • ì¶”ê°€

2. **DTOs**
   - `backend/src/main/java/ac/cbnu/heartcheck/dto/voice/TokenResponse.java` - í† í° ì‘ë‹µ DTO
   - `backend/src/main/java/ac/cbnu/heartcheck/dto/voice/OpenAITokenRequest.java` - OpenAI API ìš”ì²­ DTO
   - `backend/src/main/java/ac/cbnu/heartcheck/dto/voice/OpenAITokenResponse.java` - OpenAI API ì‘ë‹µ DTO

3. **Services**
   - `backend/src/main/java/ac/cbnu/heartcheck/service/OpenAIRealtimeService.java` - OpenAI Realtime API í†µí•© ì„œë¹„ìŠ¤

4. **Controllers**
   - `backend/src/main/java/ac/cbnu/heartcheck/controller/VoiceTestController.java` - ìŒì„± ê²€ì‚¬ API ì»¨íŠ¸ë¡¤ëŸ¬

5. **Configuration Classes**
   - `backend/src/main/java/ac/cbnu/heartcheck/config/RestTemplateConfig.java` - HTTP í´ë¼ì´ì–¸íŠ¸ ì„¤ì •

### Frontend íŒŒì¼

1. **Constants**
   - `frontend/src/constants/voiceTestQuestions.ts` - 17ê°œ ì§ˆë¬¸ ì •ì˜ ë° íŒŒì‹± ìœ í‹¸ë¦¬í‹°

2. **Services**
   - `frontend/src/services/voiceTestService.ts` - WebSocket ê¸°ë°˜ OpenAI Realtime API ì„œë¹„ìŠ¤

3. **Hooks**
   - `frontend/src/hooks/useVoiceTest.ts` - ìŒì„± ê²€ì‚¬ ìƒíƒœ ê´€ë¦¬ ë° ë¡œì§ Hook

4. **Screens**
   - `frontend/src/screens/main/VoiceTestModeScreen.tsx` - ìŒì„± ê²€ì‚¬ UI (ì™„ì „ ì¬êµ¬í˜„)

5. **Navigation**
   - `frontend/src/navigation/RootNavigator.tsx` - VoiceTestMode í™”ë©´ ë“±ë¡ (ê¸°ì¡´ íŒŒì¼ ìˆ˜ì •)
   - `frontend/src/types/index.ts` - VoiceTestMode íƒ€ì… ì¶”ê°€ (ê¸°ì¡´ íŒŒì¼ ìˆ˜ì •)

## ë‹¤ìŒ ë‹¨ê³„

### 1. ë°±ì—”ë“œ ì„œë²„ ì¬ì‹œì‘ ë° í™•ì¸ âœ…
```bash
cd backend
./gradlew bootRun
# ì„œë²„ê°€ í¬íŠ¸ 8080ì—ì„œ ì •ìƒ ì‹¤í–‰ë˜ëŠ”ì§€ í™•ì¸
```

### 2. ì‹¤ì œ ìŒì„± ê²€ì‚¬ í…ŒìŠ¤íŠ¸ ğŸ¯
```bash
# í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë‹¤ìŒ íë¦„ í…ŒìŠ¤íŠ¸:
1. í™ˆ í™”ë©´ â†’ "ìŒì„± ê²€ì‚¬ ëª¨ë“œë¡œ ì „í™˜" í´ë¦­
2. VoiceTestModeScreenì—ì„œ "ìŒì„± ê²€ì‚¬ ì‹œì‘í•˜ê¸°" í´ë¦­
3. ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©
4. OpenAI ì—°ê²° í™•ì¸ (connecting â†’ ready)
5. AI ì§ˆë¬¸ ë“£ê¸° ë° ë‹µë³€
6. 17ê°œ ì§ˆë¬¸ ì™„ë£Œ
7. ê²°ê³¼ ìë™ ì œì¶œ ë° Result í™”ë©´ ì´ë™
```

### 3. ë””ë²„ê¹… ë° ê°œì„  ì‚¬í•­
- [ ] WebSocket ì—°ê²° ì•ˆì •ì„± í…ŒìŠ¤íŠ¸
- [ ] ìŒì„± ì¸ì‹ ì •í™•ë„ í™•ì¸ (í•œê¸€ ìˆ«ì íŒŒì‹±)
- [ ] ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
- [ ] ë‹µë³€ ì¬ì‹œë„ í”Œë¡œìš° í…ŒìŠ¤íŠ¸
- [ ] ì¤‘ë‹¨/ì·¨ì†Œ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸

### 4. ì¶”ê°€ ê¸°ëŠ¥ (ì„ íƒì‚¬í•­)
- [ ] ìŒì„± ê²€ì‚¬ ì´ë ¥ ì €ì¥ (voice_test_sessions í…Œì´ë¸”)
- [ ] í†µê³„ ë° ë¶„ì„ ëŒ€ì‹œë³´ë“œ
- [ ] Rate limiting êµ¬í˜„
- [ ] ì˜¤ë””ì˜¤ í’ˆì§ˆ ìµœì í™”
- [ ] ë°±ê·¸ë¼ìš´ë“œ ëª¨ë“œ ëŒ€ì‘

### 5. í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„
- [ ] í™˜ê²½ë³„ API key ë¶„ë¦¬ (dev/staging/prod)
- [ ] ì—ëŸ¬ ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ì„¤ì •
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë° ìµœì í™”
- [ ] ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘
- [ ] ì•±ìŠ¤í† ì–´/í”Œë ˆì´ìŠ¤í† ì–´ ì—…ë°ì´íŠ¸
